# Vector Databases: A Practical Guide


## Table of Contents
1. [What is a Vector Database?](#what-is-a-vector-database)
2. [When to Use a Vector Database](#when-to-use-a-vector-database)
3. [How to Create a Vector Database with Python](#how-to-create-a-vector-database-with-python)
    - [Using PDFs, CSVs, Docs, Audio, Video](#using-pdfs-csvs-docs-audio-video)
    - [Code Examples](#code-examples)
4. [Embeddings and Indexes in Vector DB](#embeddings-and-indexes-in-vector-db)
5. [Business Use Cases](#business-use-cases)
6. [Real-world Examples](#real-world-examples)
7. [Vector DB, Semantic Search, and AI Applications](#vector-db-semantic-search-and-ai-applications)
8. [Building a Chatbot with Vector DB](#building-a-chatbot-with-vector-db)
    - [OpenAI Embeddings](#openai-embeddings)
    - [Chunking and Text Splitting](#chunking-and-text-splitting)
    - [Vector Database Operations and Features](#vector-database-operations-and-features)
    - [Use Cases](#use-cases)
    - [Examples of Vector Databases and Libraries](#examples-of-vector-databases-and-libraries)
    - [Vector Indexing and Search Algorithms](#vector-indexing-and-search-algorithms)
9. [Building a Plain Vector Database (No LLM)](#building-a-plain-vector-database-no-llm)
10. [How to Interact with a Vector Database Using Python](#how-to-interact-with-a-vector-database-using-python)
11. [ChromaDB, OpenAI, and Ollama](#chromadb-openai-and-ollama)
12. [References](#references)

---

## What is a Vector Database?
A **vector database** is a specialized database designed to store, index, and search high-dimensional vectors (numerical arrays). These vectors typically represent data such as text, images, audio, or video after being transformed by machine learning models (embeddings). Vector databases enable efficient similarity search, which is crucial for AI, recommendation systems, and semantic search.

---

## When to Use a Vector Database
- **Semantic Search:** Find similar documents, images, or audio based on meaning, not keywords.
- **Recommendation Systems:** Suggest products, content, or users based on vector similarity.
- **AI Applications:** Power chatbots, question-answering, and retrieval-augmented generation.
- **Multimedia Search:** Search across images, audio, and video using embeddings.
- **Large-scale Data:** Handle millions of items with fast similarity queries.

---

## How to Create a Vector Database with Python

### Using PDFs, CSVs, Docs, Audio, Video
You can use libraries like [ChromaDB](https://docs.trychroma.com/), [FAISS](https://github.com/facebookresearch/faiss), or [Milvus](https://milvus.io/) for vector databases. Below is an example using ChromaDB and OpenAI embeddings.

#### Install Required Libraries
```bash
pip install chromadb openai pypdf pandas
```

#### Code Examples
```python
import chromadb
from chromadb.utils import embedding_functions
import openai
import pandas as pd
from PyPDF2 import PdfReader

# Set your OpenAI API key
openai.api_key = "YOUR_OPENAI_API_KEY"

# Function to get embeddings from OpenAI
# Converts text to vector using OpenAI
# We need this to represent text semantically for similarity search
def get_embedding(text):
    response = openai.Embedding.create(input=text, model="text-embedding-ada-002")
    return response['data'][0]['embedding']

# Initialize Chroma DB
client = chromadb.Client()
collection = client.create_collection(name="documents")

# Index PDF
pdf = PdfReader("sample.pdf")
for page in pdf.pages:
    text = page.extract_text()
    embedding = get_embedding(text)
    collection.add(documents=[text], embeddings=[embedding])

# Index CSV
# We need this to search structured data semantically
# Replace 'text_column' with your actual column name
df = pd.read_csv("sample.csv")
for row in df['text_column']:
    embedding = get_embedding(row)
    collection.add(documents=[row], embeddings=[embedding])

# Index plain text docs
with open("sample.txt") as f:
    text = f.read()
    embedding = get_embedding(text)
    collection.add(documents=[text], embeddings=[embedding])

# Note: For audio/video, use a model to transcribe or extract features, then embed.
```

---

## Embeddings and Indexes in Vector DB
- **Embeddings:** Numeric representations of data (text, image, etc.) generated by ML models. They capture semantic meaning.
- **Indexes:** Data structures (like HNSW, IVF) that organize vectors for fast similarity search.

---

## Business Use Cases
- **Customer Support:** Power semantic search for FAQs and chatbots.
- **Product Recommendations:** Suggest similar products based on user behavior.
- **Content Moderation:** Detect similar harmful content.
- **Fraud Detection:** Find patterns in transaction data.

---

## Real-world Examples
- **Spotify:** Music recommendation using audio embeddings.
- **Google Photos:** Image search by content, not filename.
- **E-commerce:** Personalized product suggestions.
- **Legal/Medical:** Semantic search in large document repositories.

---

## Vector DB, Semantic Search, and AI Applications
Vector DBs enable **semantic search**—finding items by meaning, not keywords. They are foundational for AI applications like chatbots, document retrieval, and recommendation engines.

---

## Building a Chatbot with Vector DB

### OpenAI Embeddings
OpenAI provides high-quality embeddings for text, images, and more. These are used to represent user queries and documents as vectors for semantic search.

### Chunking and Text Splitting
Chunking helps break large documents into smaller pieces for better retrieval accuracy.

### Vector Database Operations and Features
- **Add:** Insert new vectors.
- **Query:** Find similar vectors.
- **Update/Delete:** Modify or remove vectors.
- **Metadata:** Store extra info with vectors.

### Use Cases
- Semantic search
- Recommendation engines
- Multimedia retrieval
- Fraud detection
- Chatbots

### Examples of Vector Databases and Libraries
- [ChromaDB](https://docs.trychroma.com/): Easy Python API, local or cloud.
- [FAISS](https://github.com/facebookresearch/faiss): Facebook’s library for fast similarity search.
- [Milvus](https://milvus.io/): Scalable, cloud-native vector DB.
- [Weaviate](https://weaviate.io/): RESTful API, supports multiple data types.

### Vector Indexing and Search Algorithms
- **HNSW (Hierarchical Navigable Small World):** Fast, scalable search.
- **IVF (Inverted File Index):** Efficient for large datasets.
- **Flat Index:** Brute-force, accurate but slow for big data.

#### Example: Chatbot with ChromaDB and OpenAI Embeddings
```python
import chromadb
from chromadb.utils import embedding_functions
import openai

# Set your OpenAI API key
openai.api_key = "YOUR_OPENAI_API_KEY"

# What is get_embedding?
# This function sends text to OpenAI's embedding API, which uses a model (text-embedding-ada-002)
# to convert the text into a high-dimensional vector (embedding). This vector captures the semantic meaning of the text.
# Why do we send text as input?
# We need to represent both our documents and user queries as vectors so we can compare them for similarity.
# What is 'text-embedding-ada-002'?
# This is an OpenAI model specifically trained to generate embeddings for text. It is widely used for semantic search and retrieval tasks.
def get_embedding(text):
    response = openai.Embedding.create(input=text, model="text-embedding-ada-002")
    # Returns a list of floats (the embedding vector) representing the input text
    return response['data'][0]['embedding']

# Chunking: Split large documents into smaller pieces for better retrieval accuracy
def chunk_text(text, chunk_size=500):
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

# Initialize ChromaDB (the vector database)
client = chromadb.Client()
collection = client.create_collection(name="chatbot_docs")

# Index documents
# For each chunk, we generate an embedding and store it in the vector DB
# This allows us to later search for similar chunks based on user queries
with open("knowledge_base.txt") as f:
    text = f.read()
    chunks = chunk_text(text)
    for chunk in chunks:
        embedding = get_embedding(chunk)
        collection.add(documents=[chunk], embeddings=[embedding])

# Chatbot query
# When a user asks a question, we:
# 1. Generate an embedding for the query (using get_embedding)
# 2. Search the vector DB for the most similar document chunks
# 3. Return those chunks as the chatbot's answer
# What does collection.query do?
# It finds the stored document chunks whose embeddings are closest to the query embedding (semantic similarity)
# Where does the LLM kick in?
# In this example, the LLM (OpenAI's embedding model) is used to generate embeddings, not to generate answers.
# For a full chatbot, you could pass the retrieved chunks to an LLM (like GPT) to generate a natural language response.
def chatbot_query(query):
    query_embedding = get_embedding(query)  # Convert user query to embedding
    results = collection.query(query_embeddings=[query_embedding], n_results=3)  # Find top 3 similar chunks
    return results['documents']  # Return the most relevant chunks

# Example usage
user_input = "How do I reset my password?"
answers = chatbot_query(user_input)
print("Chatbot answers:", answers)
```

---



## How to Interact with a Vector Database Using Python

Once your vector database is set up (with ChromaDB or similar), you can perform various operations programmatically. Here are common interactions:

### 1. Adding Documents and Vectors
```python
collection.add(documents=["New Doc"], embeddings=[[0.1, 0.2, 0.3, ...]])
# Adds a new document and its vector to the collection
```

### 2. Querying for Similarity
```python
query_vector = [0.1, 0.2, 0.3, ...]  # Your query vector
results = collection.query(query_embeddings=[query_vector], n_results=3)
print("Top matches:", results['documents'])
# Returns the top 3 most similar documents
```

### 3. Updating Documents or Vectors
```python
# ChromaDB supports upserts (update or insert)
collection.upsert(documents=["Updated Doc"], embeddings=[[0.4, 0.5, 0.6, ...]])
# Updates the vector for the given document
```

### 4. Deleting Documents
```python
collection.delete(documents=["Doc to delete"])
# Removes the document and its vector from the collection
```

### 5. Filtering with Metadata
```python
collection.add(documents=["Doc with meta"], embeddings=[[0.7, 0.8, 0.9, ...]], metadatas=[{"type": "example"}])
results = collection.query(query_embeddings=[[0.7, 0.8, 0.9, ...]], where={"type": "example"})
print("Filtered results:", results['documents'])
# Adds metadata and queries with filters
```

**Comments:**
- All operations are performed via the collection object in Python.
- You can automate ingestion, search, and management of your vector data.
- For more advanced features, see the [ChromaDB documentation](https://docs.trychroma.com/).

---

Sometimes you may want to build a vector database without using any large language model (LLM) or external embedding service. This is useful for prototyping, working with numeric data, or when you already have vector representations (e.g., from image features, sensor data, or manual encoding).

### Example: Plain Vector DB with ChromaDB

```python
import chromadb
import numpy as np

# Create some sample vectors manually or from numeric features
# Here, we use random vectors for demonstration
documents = ["Item A", "Item B", "Item C"]
vectors = [np.random.rand(10).tolist() for _ in documents]  # 10-dimensional vectors

# Initialize ChromaDB
client = chromadb.Client()
collection = client.create_collection(name="plain_vectors")

# Add documents and their vectors to the DB
for doc, vec in zip(documents, vectors):
    collection.add(documents=[doc], embeddings=[vec])

# Query: Find the most similar item to a new vector
query_vector = np.random.rand(10).tolist()
results = collection.query(query_embeddings=[query_vector], n_results=1)
print("Most similar item:", results['documents'])
```

**Comments:**
- No LLM or external API is used; vectors are created manually or from numeric features.
- This approach is useful for similarity search in numeric datasets, image features, sensor data, etc.
- You can use any method to generate vectors, as long as they are lists of numbers.

---

## ChromaDB, OpenAI, and Ollama

### What is ChromaDB?
[ChromaDB](https://docs.trychroma.com/) is an open-source vector database designed for AI and semantic search applications. It’s easy to use, supports fast similarity search, and can run locally or in the cloud. ChromaDB is popular for prototyping and production use in Python projects.

**Key Features:**
- Simple Python API
- Fast similarity search
- Supports metadata and filtering
- Integrates with popular embedding models (OpenAI, local LLMs, etc.)
- Can be used for chatbots, semantic search, recommendation, and more

### Why Do We Need OpenAI?
[OpenAI](https://platform.openai.com/docs/guides/embeddings) provides state-of-the-art embedding models (like `text-embedding-ada-002`) that convert text, images, or other data into high-dimensional vectors. These embeddings capture semantic meaning, making it possible to search by meaning rather than keywords.

**Reasons to use OpenAI embeddings:**
- High-quality, general-purpose embeddings
- Easy integration with Python and ChromaDB
- Excellent performance for semantic search and retrieval tasks

**Note:** Using OpenAI requires an API key and internet access. For privacy, cost, or local deployment, you may want to use a local LLM.

### How to Build a Vector DB with Ollama (Local LLM)
[Ollama](https://ollama.com/) is a tool for running large language models (LLMs) locally on your machine. You can use Ollama to generate embeddings without sending data to external servers.

#### Example: Using Ollama for Local Embeddings with ChromaDB

1. **Install Ollama and ChromaDB**
```bash
# Install Ollama (see https://ollama.com for details)
brew install ollama

# Start Ollama server
ollama serve

# Pull a model (e.g., llama2)
ollama pull llama2

# Install ChromaDB
pip install chromadb
```

2. **Generate Embeddings Locally with Ollama**
```python
import chromadb
import requests

# Function to get embeddings from Ollama (local LLM)
# Keeps all data local for privacy and cost control
def get_local_embedding(text):
    response = requests.post(
        "http://localhost:11434/api/embeddings",
        json={"model": "llama2", "prompt": text}
    )
    return response.json()["embedding"]

# Initialize ChromaDB
client = chromadb.Client()
collection = client.create_collection(name="local_docs")

# Index documents using local embeddings
documents = ["First document text", "Second document text"]
for doc in documents:
    embedding = get_local_embedding(doc)
    collection.add(documents=[doc], embeddings=[embedding])

# Querying
query = "Find similar docs"
query_embedding = get_local_embedding(query)
results = collection.query(query_embeddings=[query_embedding], n_results=2)
print("Results:", results['documents'])
```

**Comments:**
- This approach keeps all data local—no external API calls.
- You can use any LLM supported by Ollama for embeddings.
- Useful for privacy, cost control, and offline scenarios.

### When to Use OpenAI vs. Ollama
- **OpenAI:** Best for high-quality, general-purpose embeddings, cloud scalability, and rapid prototyping.
- **Ollama (Local LLM):** Best for privacy, cost savings, and when you need to run everything locally.

**Summary:**  
ChromaDB is a flexible vector database that works with both cloud (OpenAI) and local (Ollama) embedding models. Choose the embedding provider based on your business needs, privacy requirements, and infrastructure.

---

## References
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Milvus](https://milvus.io/)
- [Weaviate](https://weaviate.io/)
- [Ollama](https://ollama.com/)

---
